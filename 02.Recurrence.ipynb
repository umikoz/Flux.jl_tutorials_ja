{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Cells\n",
    "\n",
    "単純なフィードフォワードの場合、我々のmodel `m`は様々な入力$x_i$から予測$y_i$への単純な関数だ（例えば、各`x`はMNISTの数字で各`y`は数字のラベルかもしれない）。  \n",
    "各予測は他と完全独立で、同じ`x`を使えば同じ`y`を出す。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y₁ = f(x₁)\n",
    "y₂ = f(x₂)\n",
    "y₃ = f(x₃)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リカレントネットワークはモデルを実行するたび持ち越す隠れ状態（hidden state)を導入する。  \n",
    "モデルは実行する度、入力として古い`h`を受け取り、そして出力として新しい`h`を生成する。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h = # ... initial state ...\n",
    "h, y₁ = f(h, x₁)\n",
    "h, y₂ = f(h, x₂)\n",
    "h, y₃ = f(h, x₃)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h`に保存された情報は次の予測向けに保存され、一種のメモリのように機能することが可能だ。  \n",
    "これはまた、与えられた`x`向けに作られた予測が、以前モデルに与えられた全入力に依存することを意味する。\n",
    "\n",
    "（これは例えば、各`x`が文の1単語を示すときに大切になるかも。以前の入力が\"investment\"ではなく\"river\"の場合、\"bank\"というモデルの単語の解釈は変わるはず。）\n",
    "\n",
    "FluxのRNNサポートは数学的な観点に密接に従う。最も基本的なRNNはスタンダードな`Dense`レイヤに可能な限り近く、そして出力は隠れ状態だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.998621, 0.895587, 0.954941, -0.998973, -0.230397], [0.998621, 0.895587, 0.954941, -0.998973, -0.230397])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wxh = randn(5,10)\n",
    "Whh = randn(5,5)\n",
    "b = randn(5)\n",
    "\n",
    "function rnn(h,x)\n",
    "    h = tanh.(Wxh *x .+Whh *h .+b)\n",
    "    return h,h\n",
    "end\n",
    "\n",
    "x = rand(10) # ダミーのデータ\n",
    "h = rand(5) # 隠れ状態の初期化\n",
    "\n",
    "h,y = rnn(h,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もし数回最後の行を実行すると、入力`x`が同じでも出力`y`が少し変わることに気づくだろう。\n",
    "\n",
    "明示的に状態を管理する上記の`rnn`のような関数を時々recurrent cellsと呼ぶ。  \n",
    "[layer reference](https://fluxml.ai/Flux.jl/stable/models/layers.html)に記載された様々なリカレントセルが利用できる。  \n",
    "上述の手書きの例は以下のように置き換えることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Flux.Tracker.TrackedReal{Float64}[-0.562118 (tracked), 0.935468 (tracked), -0.438911 (tracked), -0.766244 (tracked), 0.0477802 (tracked)], Flux.Tracker.TrackedReal{Float64}[-0.562118 (tracked), 0.935468 (tracked), -0.438911 (tracked), -0.766244 (tracked), 0.0477802 (tracked)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "rnn2 = Flux.RNNCell(10,5)\n",
    "\n",
    "x = rand(10)\n",
    "h = rand(5)\n",
    "\n",
    "h,y = rnn2(h,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful Models\n",
    "\n",
    "ほとんどの場合、隠れ状態を自分で管理したくないが、ステートフルとしてモデルを扱う。  \n",
    "Fluxはこれを行うための`Recur`ラッパーを提供する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.9999651403370672\n",
       "  0.9042946920340857\n",
       "  0.7459985055259362\n",
       " -0.9646724898495012\n",
       " -0.9901382566602037"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(10)\n",
    "h = rand(5)\n",
    "\n",
    "m = Flux.Recur(rnn,h)\n",
    "y = m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recur`ラッパは`m.state`フィールドに実行中の状態を保存する。\n",
    "\n",
    "`RNN(10,5)`コンストラクタを使うなら、`RNNCell`とは対象的に、単にラップされたセルになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recur(RNNCell(10, 5, tanh))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN(10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences\n",
    "\n",
    "しばしば、個別の`x`よりも、入力のシーケンスを操作したい場合がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,1},1}:\n",
       " [0.583439, 0.270828, 0.645324, 0.582245, 0.720667, 0.0214004, 0.818235, 0.559457, 0.128958, 0.0329589]  \n",
       " [0.831522, 0.911903, 0.0958293, 0.0749957, 0.32671, 0.544972, 0.468254, 0.15952, 0.108886, 0.282196]    \n",
       " [0.853596, 0.516555, 0.304362, 0.332502, 0.871917, 0.438704, 0.73207, 0.0440479, 0.114421, 0.58646]     \n",
       " [0.706584, 0.82836, 0.147562, 0.277059, 0.224745, 0.150495, 0.659646, 0.329409, 0.975953, 0.262125]     \n",
       " [0.515368, 0.915291, 0.115958, 0.0423836, 0.0996269, 0.58182, 0.0292797, 0.772585, 0.892784, 0.43899]   \n",
       " [0.170393, 0.00682371, 0.104769, 0.541614, 0.922795, 0.91761, 0.762356, 0.492207, 0.000708282, 0.309189]\n",
       " [0.654442, 0.305286, 0.290396, 0.289599, 0.979649, 0.280325, 0.810617, 0.654364, 0.633268, 0.0709389]   \n",
       " [0.424393, 0.593553, 0.856415, 0.524709, 0.323376, 0.0663094, 0.129096, 0.273228, 0.630161, 0.0217332]  \n",
       " [0.390993, 0.821405, 0.793647, 0.231258, 0.572247, 0.113549, 0.667871, 0.614657, 0.891837, 0.708953]    \n",
       " [0.0545453, 0.727221, 0.233712, 0.956639, 0.876678, 0.997335, 0.909998, 0.422212, 0.337786, 0.0981995]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [rand(10) for i=1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recur`で、シーケンスの各要素を取り出すのは簡単。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,1},1}:\n",
       " [0.996277, 0.168987, 0.92032, -0.999943, -0.998783]   \n",
       " [0.998406, 0.724105, 0.979046, -0.999564, -0.998488]  \n",
       " [0.998487, 0.499356, 0.988834, -0.999977, -0.996953]  \n",
       " [0.998631, 0.71989, 0.517272, -0.999968, -0.996026]   \n",
       " [0.998218, 0.69676, 0.826041, -0.999136, -0.999907]   \n",
       " [0.988051, 0.953308, 0.994042, -0.999983, -0.995672]  \n",
       " [0.993837, 0.772518, 0.976913, -0.999996, -0.998035]  \n",
       " [0.999851, -0.526252, 0.0277458, -0.998774, -0.999201]\n",
       " [0.998297, 0.175353, 0.531483, -0.999383, -0.640594]  \n",
       " [0.99926, 0.983686, 0.95755, -0.999979, -0.941917]    "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これはリカレントレイヤをより大きなモデルとつなげても動作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{TrackedArray{…,Array{Float64,1}},1}:\n",
       " [-0.308895 (tracked), -0.153026 (tracked), 0.303663 (tracked), 0.263189 (tracked), -0.0972582 (tracked)]   \n",
       " [-0.359968 (tracked), 0.0343782 (tracked), 0.307313 (tracked), 0.20051 (tracked), -0.160024 (tracked)]     \n",
       " [-0.342428 (tracked), 0.128141 (tracked), 0.153618 (tracked), 0.0495365 (tracked), -0.177353 (tracked)]    \n",
       " [-0.420364 (tracked), 0.157255 (tracked), 0.149099 (tracked), -0.13621 (tracked), -0.28409 (tracked)]      \n",
       " [-0.432497 (tracked), 0.160909 (tracked), 0.208093 (tracked), -0.232505 (tracked), -0.440248 (tracked)]    \n",
       " [-0.328809 (tracked), 0.0955212 (tracked), 0.10175 (tracked), -0.168891 (tracked), -0.383068 (tracked)]    \n",
       " [-0.261597 (tracked), 0.0824081 (tracked), -0.0248293 (tracked), -0.312337 (tracked), -0.363437 (tracked)] \n",
       " [-0.260027 (tracked), -0.0305384 (tracked), -0.0334161 (tracked), -0.454462 (tracked), -0.408758 (tracked)]\n",
       " [-0.353443 (tracked), 0.00118883 (tracked), -0.0608493 (tracked), -0.574465 (tracked), -0.442484 (tracked)]\n",
       " [-0.405191 (tracked), -0.111448 (tracked), -0.0747452 (tracked), -0.535804 (tracked), -0.464123 (tracked)] "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(LSTM(10,15), Dense(15,5))\n",
    "m.(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncating Gradients\n",
    "\n",
    "デフォルトでは、リカレントレイヤの勾配計算にはそれ全体の履歴が含まれる。  \n",
    "例えば、100個の入力でモデルを呼び出すと、100個の呼び出しの勾配を計算する必要がある。  \n",
    "sらに他の10個の入力を計算すると、110個の勾配を計算しなければならない。  \n",
    "これは累積し、直ぐに（計算コストが）高価になる。\n",
    "\n",
    "これを避けるために、歴史を忘れ、勾配計算を忘却できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: truncate!\n",
    "\n",
    "truncate!(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`truncate!`の呼び出しは過去のことを水に流すので、高価な勾配計算をせずにより多くの入力でモデルを呼び出せる。\n",
    "\n",
    "`truncate!`は大きなシーケンスの複数のチャンクを扱うときは意味があるが、しかし独立したシーケンスのセットを扱いたいかもしれない。  \n",
    "その場合は、隠れ層はオリジナルの値に完全にリセットするべきで、累積された情報はすべて棄却される。  \n",
    "`reset!`は君のためにこれを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Layers\n",
    "\n",
    "[WIP]\n",
    "\n",
    "これらのコアレイヤはほぼすべてのニューラルネットワークの基盤を構成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Flux.Chain` - *Type.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "Chain(layers...)\n",
    "```\n",
    "\n",
    "与えられた入力に対し順番に呼ばれるように複数のレイヤ・関数をつなげる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m(5) == 26 = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "m = Chain(x->x^2, x->x+1)\n",
    "@show m(5) == 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m2 (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(Dense(10,5), Dense(5,2))\n",
    "x = rand(10)\n",
    "m2(x) = m[2](m[1](x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Chain`はインデクシングやスライスをサポートする。例えば`m[2]`や`m[1:end-1]`など。  \n",
    "`m[1:3](x)`は最初の３つのレイヤの出力を計算する。\n",
    "\n",
    "[source](https://github.com/FluxML/Flux.jl/blob/9d563820f8f2f5ae91364afc1e9f371f75466e77/src/layers/basic.jl#L1-L18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Flux.Dense` - *Type.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers\n",
    "---\n",
    "上述のコアレイヤに似ているが、シーケンスデータの処理に使える。（他種の構造化データも）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Flux.RNN` - *Function.*\n",
    "```julia\n",
    "RNN(in::Integer, out::Integer, σ = tanh)\n",
    "```\n",
    "最も基本的なリカレントレイヤ。`Dense`レイヤのように機能するが、出力はタイムステップごとに入力へフィードバックされる。\n",
    "\n",
    "[source](https://github.com/FluxML/Flux.jl/blob/9d563820f8f2f5ae91364afc1e9f371f75466e77/src/layers/recurrent.jl#L105-L110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "---\n",
    "モデルのレイヤ間の非線形性。  \n",
    "これらの関数の殆どは[NNlib](https://github.com/FluxML/NNlib.jl)に定義されているが、Fluxではデフォルトで使える。\n",
    "\n",
    "特記しなければ活性化関数はスカラに対して機能する。  \n",
    "配列に適用するには`σ.(xs)`、`relu.(xs)`のようにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation & Regularisation\n",
    "---\n",
    "\n",
    "これらのレイヤはネットワーク構造に影響を与えないが、トレーニング時間の改善や過学習の削減ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
